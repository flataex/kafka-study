# '정확히 한 번' 의미 구조

카프카의 ‘정확히 한 번’ 의미 구조는 두 개의 핵심 기능 (멱등적 프로듀서, 트랜잭션 의미 구조)의 조합으로 이루어진다.

**멱등적 프로듀서**는 프로듀서 재시도로 인해 발생하는 중복을 방지한다. <br>
**트랜잭션 의미 구조**는 스트림 처리 애플리케이션에서 ‘정확히 한 번’ 처리를 보장한다.

<br>
<hr>

# 멱등적 프로듀서

동일한 작업을 여러 번 실행해도 한 번 실행한 것과 결과가 같은 서비스를 **멱등적**이라고 한다.

만약 우리가 멱등성 의미 구조가 아닌 ‘최소 한 번’ 의미 구조를 가지도록 프로듀서를 설정한다면, 프로듀서가 메시지 전송을 재시도함으로써 메시지가 최소 한 번 이상 도착할 수 있는 불확실성이 존재하게 된다. <br>
카프카의 멱등적 프로듀서 기능은 자동으로 이러한 중복을 탐지하고 처리함으로써 이 문제를 해결한다.

## 멱등적 프로듀서의 작동 원리

멱등적 프로듀서 기능을 켜면 모든 메시지는 고유한 **프로듀서 ID**와 **시퀀스 넘버**를 가지게 된다. <br>
대상 토픽 및 파티션과 이 두 값을 합치면 각 메시지의 고유한 식별자가 된다. <br>
각 브로커는 해당 브로커에 할당된 모든 파티션들에 쓰여진 마지막 5개 메시지들을 추적하기 위해 이 고유 식별자를 사용한다.

브로커가 예전에 받은 적이 있는 메시지를 받게 될 경우, 적절한 에러를 발생시킴으로써 중복 메시지를 거부한다. <br>
이 에러는 프로듀서에 로깅도 되고 지푯값에도 반영이 되지만, 예외가 발생하 는 것은 아니기 때문에 사용자에게 경보를 보내지는 않는다.

## 멱등적 프로듀서의 한계

**카프카의 멱등적 프로듀서는 프로듀서의 내부 로직으로 인한 재시도가 발생할 경우 생기는 중복만을 방지한다.** <br>
동일한 메시지를 가지고 producer.send()를 두 번 호출하면 멱등적 프로듀서가 개입 하지 않는 만큼 중복된 메시지가 생기게 된다. 

> 여러 개의 인스턴스를 띄우거나 하나의 인스턴스에서 여러 개의 프로듀서를 띄우는 애플리케이션들 역시 흔하다. <br>
> 만약 이러한 프로듀서들 중 두 개가 동일한 메시지를 전송하려 시도할 경우, 멱등적 프로듀서는 중복을 잡아내지 못한다.

## 멱등적 프로듀서 사용법

프로듀서 설정에 enable.idempotence=true를 추가해주면 된다. <br>
멱등적 프로듀서 기능을 활성화시키면 다음과 같은 것들이 바뀐다.

- 프로듀서 ID를 받아오기 위해 프로듀서 시동 과정에서 API를 하나 더 호출한다. 
- 전송되는 각각의 레코드 배치에는 프로듀서 ID와 배치 내 첫 메시지의 시퀀스 넘버가 포함된다. 이 새 필드들은 각 메시지 배치에 96 비트를 추가한다
- 브로커들은 모든 프로듀서 인스턴스에서 들어온 레코드 배치의 시퀀스 넘버를 검증해서 메시지 중복을 방지한다.
- 장애가 발생하더라도 각 파티션에 쓰여지는 메시지들의 순서는 보장된다.

<br>
<hr>

# 트랜잭션

카프카의 트랜잭션 기능은 스트림 처리 애플리케이션을 위해 특별히 개발되어서, 스트림 처리 애플리케이션의 기본 패턴인 ‘읽기-처리-쓰기’ 패턴에서 사용하도록 개발되었다. <br>
트랜잭션 기능은 이런 맥락에서 ‘정확히 한 번’ 의미 구조를 보장할 수 있다.

## 트랜잭션이 해결하는 문제

원본 토픽으로부터 이벤트를 읽어서, 처리를 한 다음, 결과를 다른 토픽에 쓰는 스트림 처리 애플리케이션을 가정했을때, 우리가 처리하는 각 메시지에 대해 결과가 정확히 한 번만 쓰여지도록 하고 싶다. <br>
이 과정에서 꽤 많은 것들이 잘못될 수 있다.

### 애플리케이션 크래시로 인한 재처리

원본 클러스터로부터 메시지를 읽어서 처리한 뒤, 애플리케이션은 두 가지를 해야 한다. 즉, 하나는 결과를 출력 토픽에 쓰는 것이고 또 하나는 우리가 읽어 온 메시지의 오프셋을 커밋하는 것이다. <br>
만약 출력 토픽에는 이미 썼는데 입력 오프셋은 커밋되기 전에 애플리케이션이 크래시나면, 몇 초가 지난 후 하트비트가 끊어지면서 리밸런스가 발생하고, 컨슈머가 읽어오고 있던 파티션들은 다른 컨슈머로 재할당될 것이다. <br>
컨슈머는 새로 할당된 파티션의 마지막으로 커밋된 오프셋으로부터 레코드를 읽어오기 시작한다. (중복 발생)

### 좀비 애플리케이션에 의해 발생하는 재처리

만약 애플리케이션이 카프카로부터 레코드 배치를 읽어온 직후 뭔가를 하기 전에 멈추거나, 카프카로의 연결이 끊어진다면 어떻게 될까?

하트비트가 끊어지면서 애플리케이션은 죽은 것으로 간주될 것이며, 해당 컨슈머에 할당되어 있던 파티션들은 컨슈머 그룹 내 다른 컨슈머들에게 재할당될 것이다. <br>
파티션을 재할당받은 컨슈머가 레코드 배치를 다시 읽어서 처리하고, 출력 토픽에 결과를 쓰고, 작업을 계속한다. <br>
**그사이, 멈췄던 애플리케이션의 첫 번째 인스턴스가다시 작동할수 있다.** <br>
즉, 마지막으로 읽어 왔던 레코드 배치를 처리하고 결과를 출력 토픽에 쓰는 것이다. (중복 발생)

## 트랜잭션은 어떻게 ‘정확히 한 번’을 보장하는가?

‘읽기-처리-쓰기’ 패턴의 스트림 처리 애플리케이션에서, **정확히 한 번**이란 읽기, 처리, 쓰기 작업이 원자적으로 이루어진다는 의미다. <br>
이러한 작동을 지원하기 위해, 카브카 트랜잭션은 **원자적 다수 파티션 쓰기** 기능을 도입했다. <br>
만약 우리가 트랜잭션을 시작해서 양쪽에 메시지를 쓰고, 둘 다 성공해서 커밋할 수 있다면, 그 다음부터 그 다음부터는 ‘정확히 한 번’ 의미 구조가 알아서 해준다.

<img width="628" alt="스크린샷 2023-10-02 오후 4 01 28" src="https://github.com/flataex/kafka-study/assets/87420630/27644256-38d8-4193-b5a6-b0595873b0cc">

> 트랜잭션을 사용해서 원자적 다수 파티션 쓰기를 수행하려면 **트랜잭션적 프로듀서**를 사용해야 한다. <br>
> 카프카 브로커에 의해 자동으로 생성 되는 producer.id와는 달리 transactional.id 프로듀서 설정의 일부이며, 재시작을 하더라도 값이 유지된다.

> 애플리케이션의 좀비 인스턴스가 중복 프로듀서를 생성하는 것을 방지하려면 **좀비 펜싱** 혹은 애플리케이션의 좀비 인스턴스가 출력 스트림에 결과를 쓰는 것을 방지할 필요가 있다. <br>
> 일반적으로 좀비 펜싱 방법인 에포크를 사용하는데, 카프카는 트랜잭션적 프로듀서가 초기화를 위해 initTransaction()를 호출하면 transactional.id에 해당하는 에포크 값을 증가시킨다. <br>
> 같은 transactional.id를 가지고 있지만 에포크 값은 낮은 프로듀서가 메시지 전송, 트랜잭션 커밋, 트랜잭션 중단 요청을 보낼 경우 FencedProducer 에러가 발생하면서 거부된다. <br>
> 오래된 프로듀서는 출력 스트림을 쓰는 것이 불가능하기 때문에 close()를 호출해서 닫아주는 것 외에는 방법이 없다. 즉, 좀비가 중복 레코드를 쓰는 것은 불가능하다.

<br>

트랜잭션 기능을 사용해서 쓰여진 레코드는 비록 결과적으로 중단된 트랜잭션에 속할지라도 다른 레코드들과 마찬가지로 파티션에 쓰여진다. <br>
컨슈머에 올바른 격리 수준이 설정되어 있지 않을 경우, 우리가 기대하는 ‘정확히 한 번’ 보장은 이루어지지 않을 것이다.

우리는 isolation.level 설정값을 잡아줌으로써 트랜잭션 기능을 써서 쓰여진 메시지들을 읽어오는 방식을 제어할 수 있다. <br>
아래 그림은 기본값인 read_uncommitted 모드로 설정된 컨슈머와 비교할 때 read_committed 모드 컨슈머에서 어떤 레코드들이 보여지는지를 보여준다. <br>
메시지의 읽기 순서를 보장하기 위해 read_committed 모드에서는 아직 진행중인 트랜잭션이 처음으로 시작된 시점 이후에 쓰여진 메시지는 리턴되지 않는다. <br>


<img width="600" alt="스크린샷 2023-10-02 오후 4 06 44" src="https://github.com/flataex/kafka-study/assets/87420630/3b97905b-0d89-4194-8d1d-da326cee8d44">

## 트랜잭션으로 해결할 수 없는 문제들

다음은 카프카의 트랜잭션 기능이 ‘정확히 한 번’ 보장에 도움이 되지 않는 몇 가지 경우다.

### 스트림 처리에 있어서의 부수 효과

스트림 처리 애플리케이션의 처리 단계에 사용자에 이메일을 보내는 작업이 포함되어 있다고 해 보자. <br>
레코드 중복을 방지하기 위해 시퀀스 넘버를 사용하는 것이나 트랜잭션을 중단 혹은 취소하기 위해 마커를 사용하는 것은 카프카 안에서만 작동하는 것이지, <br>
이메일 발송을 취소시킬 수 있는 것은 아니기 때문에 이메일이 한 번만 발송되는 것은 아니다.

### 카프카 토픽에서 읽어서 데이터베이스에 쓰는 경우

레코드는 JDBC와 같은 데이터베이스 드라이버를 통해 데이터베이스에 쓰여지 고, 오프셋은 컨슈머에 의해 카프카에 커밋된다. <br>
하나의 트랜잭션에서 외부 데이터베이스에는 결과를 쓰고 카프카에는 오프셋을 커밋할 수 있도록 해주는 메커니즘 같은 건 없다. <br>
*대신, 오프셋을 데이터베이스에서 저장하도록 할 수는 있다. 이렇게 하면 하나의 트랜잭션에서 데이터와 오프셋을 동시에 데이터베이스에 커밋할 수 있다.*

### 한 클러스터에서 다른 클러스터로 데이터 복제

하나의 카프카 클러스터에서 다른 클러스터로 데이터를 복사할 때 ‘정확히 한 번’을 보장할 수 있다. <br>
하지만 이것이 트랜잭션의 원자성을 보장하지는 않는다. <br>
만약 애플리케이션이 여러 개의 레코드와 오프셋을 트랜잭션적으로 쓰고, 미러메이커 2.0이 이 레코드들을 다른 카프카 클러스터에 복사한다면, 복사 과정에서 트랜잭션 속성이나 보장 같은 것은 유실된다.

### 발행/구독 패턴

발행/구독 패턴에 트랜잭션을 사용 할 경우 몇 가지 보장되는 것이 있기는 하다. <br>
read_committed 모드가 설정된 컨슈머들은 중단된 트랜잭션에 속한 레코드들을 보지 못할 것이다. <br>
하지만 이러한 보장은 ‘정확히 한 번’에 미치지 못한다. 오프셋 커밋 로직에 따라 컨슈머들은 메시지를 한 번 이상 처리할 수 있다.

이 경우 카프카가 보장하는 것은 JMS 트랜잭션에서 보장하는 것과 비슷하지만, 커밋되지 않은 트랜 잭션들이 보이지 않도록 컨슈머들에 read_committed 설정이 되어 있어야 한다는 전제 조건이 붙는다. <br>
JMS 브로커들은 모든 컨슈머에게 커밋되지 않은 트랜잭션의 레코드를 주지 않는다.

## 트랜잭션 사용법

트랜잭션 기능을 사용하는 가장 일반적이고도 권장되는 방법은 카프카 스트림즈에서 exactly-once 보장을 활성화하는 것이다. <br>
이렇게 하면 트랜잭션 기능을 직접적으로 사용할 일은 전혀 없지만, 카프카 스트림즈가 대신 해당 기능을 사용해서 우리가 필요로 하는 보장을 제공해 준다.

만약 카프카 스트림즈를 사용하지 않고 ‘정확히 한 번’ 보장을 사용하고 싶다면 트랜잭션 API를 직접 사용한다. [예제](https://github.com/apache/kafka/blob/trunk/examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java)

## 트랜잭션 ID와 펜싱

트랜잭션 ID를 잘못 할당해 줄 경우 애플리케이션에 에러가 발생하거나 ‘정확히 한 번’ 보장을 준수할 수 없게 될 수도 있다. <br>
여기서 핵심 요구 조건은 트랜잭션 ID가 동일 애플리케이션 인스턴스가 재시작 했을 때는 일관적으로 유지되는 반면, 서로 다른 애플리케이션 인스턴스에 대해서는 서로 달라야 한다는 점이다. <br>
그렇지 않으면 브로커는 좀비 인스턴스의 요청을 쳐내지 못할 것이다.

<img width="626" alt="스크린샷 2023-10-02 오후 4 21 58" src="https://github.com/flataex/kafka-study/assets/87420630/452f39e5-ad75-4343-bca9-3a5e30a84b68"> <br>
<img width="636" alt="스크린샷 2023-10-02 오후 4 22 02" src="https://github.com/flataex/kafka-study/assets/87420630/9f36731f-ca0a-4472-87e5-b03cbe8a463b">

토픽 T1에 두 개의 파티션, t-0과 t-1이 있다고 가정해보자. <br>
이들 각각은 동일한 컨슈머 그룹에 속한 서로 다른 컨슈머가 읽고 있으며, 각 컨슈머는 읽어 온 레코드를 트랜잭션적 프로듀서에게 넘겨준다. <br>
그리고 이들은 각각 토픽 T2의 파티션 0과 1에 결과물을 쓴다.

컨슈머 A와 프로듀서 A가 포함된 애플리케이션 인스턴스가 좀비가 되고, 컨슈머 B가 두 파티션으로부터의 레코드를 모두 처리하기 시작했다고 하자. <br>
만약 어떤 좀비도 파티션 0에 레코드를 쓰지 못하게 하고 싶다면, 컨슈머 B가 파티션 0을 읽어서 트랜잭션 ID가 B인 프로듀서가 또 다른 파티션 0으로 쓰는 작업 역시 바로 시작할 수 없다. <br>
대신, 애플리케이션은 기존 프로듀서의 쓰 기를 펜싱하고 파티션 0에 무사히 쓰기 작업을 수행하기 위해 트랜잭션 ID가 A인 새 프로듀서를 생성해야 할 것이다. <br>
이것은 낭비다. 대신, 트랜잭션에 컨슈머 그룹 정보를 포함한다. <br>
이제 프로듀서 B로부터의 트랜잭션은 다음 세대의 컨슈머 그룹에서 온 것이 명백하므로 문제없이 작업을 진행할 수 있다. <br>
대신 (좀비가 된) 프로듀서 A로부터의 트랜잭션은 이전 세대의 컨슈머 그룹에서 온 것인 만큼 펜싱된다.

<br>
<hr>









