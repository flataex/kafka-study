# 스트림 처리

카프카는 카프카 스트림즈라 불리는 강력한 스트림 처리 라이브러리를 클라이언트 라이브러리의 일부로서 포함한다. <br>
카프카 스트림즈를 사용하면 외부 처리 프레임워크에 의존할 필요 없이 애플리케이션에 이벤트를 읽고, 처리하고, 쓰는 기능을 구현할 수 있다.

## 스트림 처리란 ?

**데이터 스트림**이란 무한히 늘어나는 데이터 세트를 추상화한 것이다. <br>
시간이 흐름에 따라 새로운 레코드가 계속해서 추가되기 때문에 데이터세트가 무한해지는 것이다.

### 이벤트 스트림에는 순서가 있다.

> 이벤트는 그 자체로 다른 이벤트 전에 혹은 후에 발생했다는 의미를 가진다. <br>
> 계좌에 입금한 뒤 나중에 출금하는 것은 출금 먼저 하고 부채 상환을 위해 나중에 입금하는 것과 완전히 다르다. <br>
> 후자의 경우 초과 인출 요금이 발생하지만 전자는 그렇지 않은 것이다.

### 데이터 레코드는 불변하다.

> 이벤트는 한 번 발생한 뒤에는 절대로 고칠 수 없다. 취소된 금융 거래는 사라지지 않는다. <br>
> 고객이 사갔던 상품을 반품할 경우, 이 상품이 과거에 팔렸다는 사실을 삭제하는 대신 반품을 추가 이벤트로 기록한다.

### 이벤트 스트림은 재생이 가능하다.

> 대부분의 애플리케이션에서 재생이 불가능한 스트림을 생각하는 것이 어려운 일은 아니지만（소켓을 통해 들어오는 TCP 패킷은 보통 재생이 불가능하다） <br>
> 몇 달 전, 심지어 몇 년 전에 발생한 raw stream을 그대로 재생할 수 있다는 것은 매우 중요하다. <br>
> 에러를 수정하거나, 새로운 분석 방법을 시도하거나, 혹은 감사를 수행하기 위해 필요하기 때문이다.

<br>

스트림 처리는 연속적이고 nonblocking하게 작동하는 방식이다. <br>
대부분의 비즈니스 프로세스는 연속적으로 발생하며, 비즈니스 리포트가 지속적으로 업데이트되고 <br>
최일선의 비즈니스 애플리케이션들이 역시 계속해서 응답할 수만 있다면 굳이 수 밀리초 내의 응답 같은 걸 기다릴 필요 없이 처리를 진행할 수 있다.

의심스러운 신용카드 결제나 네트워크 사용 내역을 알린다든가, <br>
수요와 공급에 맞춰 실시간으로 가격을 조정한다든가, 물품 배송을 추적하는 것 등이 **연속적이지만 논블로킹한 처리**에 딱 맞는다.


> 이러한 스트림 처리에 대한 정의가 특정한 프레임워크나 API, 기능을 요구하지는 않는다. <br>
> 무한한 크기의 데이터세트에서 연속적으로 데이터를 읽어와서, 뭔가를 하고, 결과를 내보내는 한 우리는 스트림 처리를 수행하고 있는 것이다. *(단, 이것이 지속적으로 계속되어야 한다.)*


<br>
<hr>

## 스트림 처리 개념

### 토폴로지

스트림 처리 애플리케이션은 하나 이상의 처리 **토폴로지**를 포함한다. <br>
하나의 처리 토폴로지는 하나 이상의 **소스 스트림**, **스트림 프로세서의 그래프**, 하나 이상의 **싱크 스트림**이 서로 연결된 것으로 <br>
하나 이상의 소스 스트림에서 시작된 이벤트 스트림은 연결된 스트림 프로세서들을 거쳐가면서 처리되다가 마지막에는 하나 이상의 싱크 스트림에 결과를 쓰는 것으로 끝나게 된다. <br>
각각의 스트림 프로세서는 이벤트를 변환하기 위해 이벤트 스트림에 가해지는 연산 단계라고 할 수 있다.

### 시간

스트림 처리의 맥락에서, 대부분의 스트림 애플리케이션이 시간 윈도우에 대해 작업을 수행하는 만큼 시간에 대해 공통적인 개념을 가지는 것은 중요하다.

예를 들어, 최근 5분 사이의 주가의 이동 평균을 구하는 스트림 애플리케이션을 생각해 보자. <br>
이 경우 데이터를 쓰는 쪽 프로세스가 네트워크 문제로 인해 두 시간 동안 오프라인 상태였다가 두 시간치 데이터를 한꺼번에 리턴할 때 무엇을 해야 할지 알아야 한다. <br>
대부분의 데이터는 일찌감치 지나가서 연산 결과가 이미 어딘가에 저장되었을 5분 길이의 시간 윈도우에 대해서나 의미가 있을 것이다.

### 상태

각각의 이벤트를 따로따로 처리해야만 한다면 스트림 프로세싱은 매우 간단해진다. <br>
하지만 스트림 처리는 다수의 이벤트가 포함되는 작업을 할 때 재미있어진다. *(이벤트를 종류별로 집계한다거나, 이동 평균을 계산하거나 등..)* <br>
이러한 경우 각각의 이벤트 자체만을 살펴보는 것만으로는 충분하지 않다. <br>
지금 한 시간 동안 발생한 타입별 이벤트 수나 조인, 합계 및 평균을 계산해야 하는 모든 이벤트 등 더 많은 정보를 추적 관리해야 하는 것이다. (이런 정보를 **상태**라 부른다.) <br>
***스트림 처리 애플리케이션의 로컬 변수에 상태를 저장하면 된다고 생각할 수도 있다.***

### 스트림 - 테이블 이원성

우리는 데이터베이스 테이블에 익숙하다. <br>
우리는 데이터베이스의 CUSTOMERS_CONTACTS 테이블을 쿼리함으로써 현재 시점에서의 모든 고객 연락처를 찾을 수 있다. <br>
하지만 테이블이 과거의 변경 내역을 저장하도록 특별히 설계되지 않았다면, 과거 연락처는 찾을 수 없을 것이다.

테이블과는 달리, 스트림은 변경 내역을 저장한다. 스트림은 변경을 유발하는 이벤트의 연속이다. <br>
테이블은 여러 상태 변경의 결과물인 현재 상태를 저장한다. 이러한 점에서 볼 때 스트림과 테이블은 같은 동전의 양면임이 명백하다.

### 시간 윈도우

대부분의 스트림 작업은 시간을 윈도우라 불리는 구간 단위로 잘라서 처리한다. <br>
이동 평균을 계산하거나, 이번 주 가장 많이 팔린 상품을 계산하는 식이다. <br>
두 스트림을 조인하는 작업 역시 윈도우 작업이다.

### 처리 보장

스트림 처리 애플리케이션에 있어서 핵심적인 요구 조건 중 하나는 장애가 발생했을 경우에도 각각의 레코드를 한 번만 처리할 수 있는 능력이다. <br>
**정확히 한 번** 보장이 없는 경우 스트림 처리는 정확한 결과가 요구되는 상황에서 사용될 수 없다. <br>
카프카 스트림즈는 카프카의 트랜잭션 기능을 사용해서 스트림 처리 애플리케이션에 **정확히 한 번** 보장을 지원한다. <br>
카프카 스트림즈 라이브러리를 사용하는 모든 애플리케이션은 processing.guarantee 설정을 exactly_once로 잡아줌으로써 정확히 한 번 보장 기능을 활성화시킬 수 있다.

<br>
<hr>

## 스트림 처리 디자인 패턴

### 단일 이벤트 처리

가장 단순한 스트림 처리 패턴은 각각의 이벤트를 개별적으로 처리하는 것이다. <br>
이것은 맵/필터 패턴이라고도 하는데, 이 패턴이 불필요한 이벤트를 스트림에서 걸러 내거나 각 이벤트를 변환하기 위해 사용되는 경우가 많기 때문이다.

이 패턴에서 스트림 처리 애플리케이션은 스트림의 이벤트를 읽어와서 각각의 이벤트를 수정한 뒤, 수정된 이벤트를 다른 스트림에 쓴다. <br>
각각의 이벤트가 독립적으로 처리될 수 있기 때문에, 이러한 애플리케이션은 애플리케이션 안에 상태를 유지할 필요가 없다. <br>
상태를 복구할 필요도 없기 때문에 장애 복구나 부하 분산이 매우 쉽다는 의미다. 그냥 다른 애플리케이션 인스턴스가 이벤트를 넘겨받아 처리하게 하면 된다.

<img width="600" alt="스크린샷 2023-10-22 오후 3 20 10" src="https://github.com/flataex/kafka-study/assets/87420630/03599105-9b12-4f05-ac1a-c1df04ff66c8">

### 로컬 상태와 스트림 처리

대부분의 스트림 처리 애플리케이션은 정보의 집계에 초점을 맞춘다. <br>
매일의 주식 최저가와 최고가를 찾고 주가의 이동평균을 구하는 것이 이러한 애플리케이션의 예가 될 것이다.

이처럼 집계를 할 때는 스트림의 상태를 유지할 필요가 있다. <br>
주식의 일별 최저가와 평균가를 계산하기 위해서는 최소값과 총합, 그리고 지금까지의 본 레코드 수를 저장해 놓아야 한다.

이 예제에서 각각의 작업은 그룹별 집계이기 때문에 이것은 공유 상태가 아닌 로컬 상태에서 수행할 수 있다. <br>
전체 주식이 아닌 주식 종목별로 분류를 해야 한다는 것이다. <br>

> 우선 카프카 파티셔너를 사용해서 동일한 주식에 대한 모든 이벤트가 동일한 파티션에 쓰여지도록 할 수 있다. <br>
> 그 다음에 각각의 애플리케이션 인스턴스는 자신에게 할당된 파티션에 저장된 모든 이벤트를 읽어온다. <br>
> 애플리케이션의 각 인스턴스는 자신에게 할당된 파티션에 쓰여진 전체 주식 종목의 부분집합에 대한 상태를 유지할 수 있다는 것이다.

<img width="685" alt="스크린샷 2023-10-22 오후 3 23 21" src="https://github.com/flataex/kafka-study/assets/87420630/6c9c16f9-f84e-40bb-a10e-48a21a0a6ce8">

<br>

스트림 처리 애플리케이션이 고려해야 할 사항에는 다음과 같은 것들이 있다.

#### 🔆 메모리 사용

로컬 상태는 애플리케이션 인스턴스가 사용 가능한 메모리 안에 들어갈 수 있는 게 이상적이다. <br>
어떤 로컬 저장소는 디스크에 내용물을 저장하는 기능을 지원하지만, 이 기능은 성능에 상당한 영향을 미친다.

#### 🔆 영속성

우리는 애플리케이션 인스턴스가 종료되었을 때 상태가 유실되지 않을뿐더러 인스턴스가 재실행되거나 다른 인스턴스에 의해 대체되었을 때 복구될 수 있음을 확신할 수 있어야 한다. <br>
카프카 스트림즈는 내장된 RocksDB를 사용함으로써 로컬 상태를 인메모리 방식으로 저장함과 동시에 재시작 시 빠르게 복구가 가능하도록 디스크에 데이터를 영속적으로 저장한다.

하지만 로컬 상태에 대한 모든 변경 사항은 카프카 토픽에도 보내진다. <br>
만약 스트림 처리를 담당하고 있는 노드에 장애가 발생한다 하더라도 로컬 상태는 유실되지 않는다. (카프카 토픽으로부터 이벤트를 읽어옴으로써 쉽게 복구 가능) <br>

#### 🔆 리밸런싱

파티션은 이따금 서로 다른 컨슈머에게 다시 할당될 수 있다. <br>
재할당이 발생하면 파티션을 상실한 애플리케이션 인스턴스는 마지막 상태를 저장함으로써 해당 파티션을 할당받은 인스턴스가 재할당 이전 상태를 복구시킬 수 있도록 해야 한다.

### 다단계 처리 / 리파티셔닝

사용 가능한 모든 정보를 사용해서 내야 하는 결과가 필요하다면 어떨까 ? 예를 들어서, 매일 상위 10개 주식을 계산해야 한다고 가정하자. <br>
상위 10개 주식 전체가 서로 다른 인스턴스에 할당된 파티션에 분산되어 있을 수 있는 탓에 이 경우 각각의 애플리케이션 인스턴스에서 따로 작업하는 것으로는 충분하지 않다. <br>
이 경우, **주식별로 하루 동안의 상승/하락을 산출**하고, **하나의 파티션만 가진 새로운 토픽에 결과를 쓴다.** <br>
그리고 이 파티션을 하나의 애플리케이션 인스턴스에서 읽어서 매일 상위 10개 주식을 찾는다. <br>
각 주식의 일별 등락만을 포함하는 두 번째 토픽은 당연히 전체 거래 내역을 포함하는 토픽에 비해 크기도 트래픽도 훨씬 작기 때문에, 단일 인스턴스만 가지는 애플리케이션만으로도 충분히 처리할 수 있다.

<img width="687" alt="스크린샷 2023-10-22 오후 3 35 40" src="https://github.com/flataex/kafka-study/assets/87420630/fa80f20c-adb2-49d5-a0a1-36f7189029aa">

### 외부 검색을 사용하는 처리: 스트림-테이블 조인

스트림 처리를 할 때 때로는 외부 데이터를 스트림과 조인해야 한다. <br>
거래 내역을 데이터베이스에 저장된 규칙을 사용해서 검증하거나 사용자 클릭 내역을 클릭한 사용자 정보와 합쳐서 확장하는 것 등이 예가 될 수 있겠다.

<img width="437" alt="스크린샷 2023-10-22 오후 3 37 32" src="https://github.com/flataex/kafka-study/assets/87420630/59b9f268-8d96-4656-a26d-511eacf679db">

여기서 문제는, 외부 검색이 각각의 레코드를 처리하는 데 있어서 상당한 지연을 발생시킨다는 것이다. <br>
스트림 처리 시스템은 보통 초당 10만 ~ 50만 개의 이벤트를 처리할 수 있는 데 반해, 데이터베이스는 초당 1만 개 가량의 이벤트를 처리할 수 있는 게 보통이기 때문이다.

성능과 가용성의 두 마리 토끼를 잡기 위해서는 스트림 처리 애플리케이션 안에 데이터베이스에 저장된 데이터를 캐시할 필요가 있다. <br>
문제는 이 캐시를 관리하는 게 만만치 않을 수 있다는 것이다. 어떻게 하면 캐시의 정보가 만료되지 않도록(혹은, 항상 최신으로 유지) 할 수 있을까 ?

하지만 만약 데이터베이스 테이블에 가해지는 모든 변경점을 이벤트 스트림에 담을 수 있다면, 스트림 처리 작업이 이 스트림을 받아와서 캐시를 업데이트 하는 데 사용하도록 할 수 있다. <br>
데이터베이스의 변경 내역을 이벤트 스트림으로 받아오는 것을 CDC라고 하며, 카프카 커넥트는 CDC를 수행하여 데이터베이스 테이블을 변경 이벤트 스트림으로 변환할 수 있는 커넥터가 여럿 있다. <br>
이를 사용하면 테이블의 복사본을 따로 유지할 수 있는 동시에 데이터베이스 변경 이벤트가 발생할 때마다 알림을 받아서 테이블 복사본을 적절히 업데이트할 수 있다.

<img width="808" alt="스크린샷 2023-10-22 오후 3 40 39" src="https://github.com/flataex/kafka-study/assets/87420630/feecc5f8-a12c-48c1-b3c2-764132676241">

### 테이블-테이블 조인

두 개의 테이블을 조인하는 것은 언제나 윈도우 처리되지 않는 연산이며, 작업이 실행되는 시점에서의 양 테이블의 현재 상태를 조인한다. <br>
카프카 스트림에서는 동일한 방식으로 파티션된 동일한 키를 가지는 두 개의 테이블에 대해 동등 조인을 수행할 수 있고, <br>
이렇게 함으로써 조인 연산이 많은 수의 애플리케이션 인스턴스와 장비에 효율적으로 분산될 수 있게 한다.

카프카 스트림즈는 역시 두 개의 테이블에 대해 외래 키 조인을 지원한다. <br>
한 스트림 혹은 테이블의 키와 다른 스트림 혹은 테이블의 임의의 필드를 조인할 수 있는 것이다.

### 스트리밍 조인

때로는 스트림과 테이블이 아닌, 두 개의 실제 이벤트 스트림을 조인해야 할 경우가 있다. <br>
두 개의 스트림을 조인할 경우 한쪽 스트림에 포함된 이벤트를 같은 키값과 함께 같은 시간 윈도우에 발생한 다른 쪽 스트림 이벤트와 맞춰야 하기 때문에 과거와 현재의 이벤트 전체를 조인하게 된다.

예를 들어, 우리 웹 서비스에 접속한 사용자들이 입력한 검색 쿼리를 담은 스트림과 검색 결과 클릭 내역을 포함한, 클릭 내역을 담은 스트림을 조인한다고 해보자. <br>
이 경우 어느 검색 결과가 가장 인기 있었는지를 알기 위해 검색 쿼리와 사용자가 클릭한 검색 결과를 맞춰보고 싶을 수 있다. <br>
**검색 기간을 기준으로 하되 특정한 시간 윈도우 범위 안에 있는 검색 결과하고만 맞춰야 한다.** <br>
우리는 쿼리가 우리의 검색 엔진에 들어온 지 몇 초 뒤에 결과가 클릭될 것이라고 가정할 수 있다. <br>
따라서 우리는 각 스트림에 대해서 몇 초 정도의 길이를 가지는 윈도우를 유지하면서 각 윈도우에 속한 이벤트끼리 맞춰줘야 한다.

<img width="648" alt="스크린샷 2023-10-22 오후 3 45 24" src="https://github.com/flataex/kafka-study/assets/87420630/3eca79a4-9841-4f58-b246-e856ee2490a2">

### 비순차 이벤트

잘못된 시간에 스트림에 도착한 이벤트를 처리하는 것은 어려운 일이다. <br>
비순차 이벤트는 상당히 자주 발생할 수 있으며, 사물 인터넷 환경에서는 더욱 그렇다. <br>
예를 들어서, 몇 시간 동안 WiFi 신호가 끊긴 모바일 장치는 재접속할 때 몇 시간치의 이벤트를 한꺼번에 전송한다.

스트림 애플리케이션은 이러한 상황을 처리할 수 있어야 한다.

- 이벤트가 순서를 벗어났음을 알아차릴 수 있어야 한다. 이를 위해서는 애플리케이션이 이벤트 시간을 확인해서 현재 시각보다 더 이전인지를 확인할 수 있어야 한다.
- 비순차 이벤트의 순서를 복구할 수 있는 시간 영역을 정의한다. 3시간 정도면 복구가 가능하지만, 3주 이상 오래된 것은 포기하는 식이다.
- 순서를 복구하기 위해 이벤트를 묶을 수 있어야 한다. 계속해서 돌아가는 동일한 프로세스가 주어진 시점 기준으로 오래된 이벤트와 새로운 이벤트를 모두 처리해야 한다.
- 결과를 변경할 수 있어야 한다. 스트림 처리의 결과가 데이터베이스에 쓰여질 경우, 결과를 변경 하는 데 put 혹은 update 정도면 충분할 것이다.

<br>
<hr>

## 예제로 보는 카프카 스트림즈

### 주식 시장 통계

주식의 종목코드, 호가와 수량을 포함하는 주식 시장 거래 이벤트 스트림을 읽어올 것이다. <br>
예를 단순하게 하기 위해서, 매수 쪽은 완전히 무시할 것이다. <br>
데이터에 타임스탬프도 포함하지 않고 카프카 프로듀서가 부여하는 이벤트 시간을 대신 사용할 것이다.

그리고 다음과 같은 윈도우가 적용된 통계값을 포함하는 결과 스트림을 생성한다.

- 5초 단위 시간 윈도우별로 가장 좋은(최저) 매도가
- 5초 단위 시간 윈도우별 거래량
- 5초 단위 시간 윈도우별 평균 매도가

모든 통계값은 매초 갱신된다.

<img width="804" alt="스크린샷 2023-10-22 오후 3 58 10" src="https://github.com/flataex/kafka-study/assets/87420630/51c7b32c-48db-48fa-9dfe-616bbaa5e98b">

1. 입력 토픽에서 이벤트를 읽어 와서 groupByKey()를 실행하는 것부터 시작한다.
2. 윈도우를 정의한다. 이 경우, 윈도우는 5초의 길이를 가지고 있으며 매초 전진한다.
3. 데이터가 원하는 대로 파티셔닝되고 윈도우도 적용되었다면, 집계 작업을 시작한다.
4. 그 다음에 실제로 집계를 수행하는 메서드를 지정한다. 이 경우 새로운 레코드를 생성함으로써 해당 윈도우에서의 최저 매도가, 거래량, 그리고 매도 총량을 업데이트하기 위해 TradeStats 객체의 add 메서드가 사용되었다.
5. 윈도우가 적용된 집계 작업에서는 상태를 저장할 로컬 저장소를 유지할 필요가 있다. aggregate 메서드의 마지막 파라미터는 상태 저장소 설정이다.
6. 상태 저장소 설정의 일부로서, 집계 결과（Tradestats）를 직렬화/역직렬화하기 위한 Serde 객체 역시 지정해주어야 한다.
7. 집계 결과는 종목 기호와 시간 윈도우를 기본 키로, 집계 결과를 밸류값으로 하는 테이블이 된다.
8. 마지막으로 할 일은 평균 가격을 갱신해주는 것이다. 현재 시점에서 집계 결과는 가격과 거래량의 합계를 포함한다. 이 레코드들을 사용해서 평균 가격을 계산한 뒤 출력 스트림으로 내보낼 수 있다.
9. 결과를 stockstats-output 스트림에 쓴다.


<br>
<hr>










